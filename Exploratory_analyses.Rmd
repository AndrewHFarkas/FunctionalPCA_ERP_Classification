---
title: 'Exploratory analyses'
author: Andrew H. Farkas
date: "`r format(Sys.time(), '%e %B, %Y')`"
output:
  html_notebook: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(fdapace)
library(fda)
#library(bestglm)
#library(caret)
#library(glmnet)

# Make standard error function
se <- function(vec, na.rm = FALSE) {
  sd(vec, na.rm)/sqrt(n())
}

#options("scipen"=100, "digits"=4)
```

# example

```{r}
data("CanadianWeather")
str(CanadianWeather)
```

Let’s focus on log-transformed average daily precipitation of Vancouver (one observed curve).

```{r}
y.lprec <- CanadianWeather$dailyAv[,,3]
l <- which(CanadianWeather$place == "Vancouver")
y <- y.lprec[,l]
day <- 1:365
plot(day, y, 
     type='o', pch = 16, cex = 0.5, col='royalblue2',
     xlab="day", ylab="log-precipitation",
     main="Log of daily average precipitation of Vancouver")
```

Now let’s try to smooth the observed points using the Fourier basis. To use the Fourier basis we need to define the domain, period, and the number of basis.

```{r}
rangval=range(day) ; period = 365 

nbasis = 3 
fbasis=create.fourier.basis(rangval, nbasis=nbasis, period=period)  
bvals = eval.basis(day, fbasis)
Xbasis =bvals; 

## fits linear regression on basis functions (OLS)

lm.fit = lm(y ~ 0 + Xbasis)   
y.fit = lm.fit$fitted.values; coef= lm.fit$coefficient

# graph won run unless in script form outside of Rmarkdown
par(mfrow=c(2,1))
plot(day, y, type="n",lwd=4, col="black",
     xlab="day", ylab="log-precipitation", 
     main=paste(nbasis, "Fourier fns"), cex=1)
points(day, y, pch=1, cex=.5, col="blue", lwd=1)
lines(day, lm.fit$fitted.values, lwd=1, col="red")

## Second Derivative of the fit evaluated at day

yfitfd = fd(coef,fbasis)  #obtain FD object
yfit2D = eval.fd(day, yfitfd, 2) # evaluate the 2nd deriv. of the fit at day

plot(day, yfit2D, type="l",lwd=2, col="black", 
     xlab="day", ylab="2D log-precipitation", 
     main=paste("mean squares of 2D log-precp. = ", 
                round(mean(yfit2D^2),2)))
```

# Try example on my data

```{r}
load(file = "C:/Users/andre/Documents/R/data/mas_dat.Rdata")
```

```{r}
electrode_used <- 31
```


```{r}
mas_dat_1elec <- mas_dat %>% filter(electrode == electrode_used)
```


```{r}
y_mas <- mas_dat_1elec[10,5:ncol(mas_dat_1elec)]

time_ms <- names(mas_dat_1elec)[5:ncol(mas_dat_1elec)] %>% as.numeric()

tibble(y_mas = unlist(y_mas),
       time_ms = time_ms) %>% 
  ggplot() +
  geom_point(aes(x = time_ms, y = y_mas)) +
  theme_classic() +
  ggtitle("Pz response to erotica")

```


```{r}
range_time <- range(time_ms)
#breaks = seq(-100, max(range_time), 50)
#breaks <- seq(-100,2000,25)
breaks <- c(-100, 0, 
            seq(5,100,5), 
            seq(110, 300, 10), 
            seq(350, 900, 50),
            seq(1000, 2000, 100))


bspline_basis <- create.bspline.basis(rangeval = range_time,
                                      # nbasis = 42,
                                      norder = 3,
                                      breaks = breaks)

#unclear if this is the correct thing to do for bspline
b_vals <- eval.basis(time_ms, bspline_basis)
X_basis <- b_vals

lm_fit <- lm(unlist(y_mas) ~ 0 + X_basis)
y_fit <- lm_fit$fitted.values
coef_bspline <- lm_fit$coefficients

tibble(y_mas = unlist(y_mas),
       y_fit = y_fit,
       time_ms = time_ms) %>% 
  ggplot() +
  geom_point(aes(x = time_ms, y = y_mas)) +
  geom_line(aes(x = time_ms, y = y_fit), 
            size = 2, 
            color = "red",
            alpha = .5) +
  geom_vline(xintercept = breaks, size = .1, alpha =.5) + 
  theme_classic() +
  ggtitle("Pz response to erotica")

```


# Example of FPCA

```{r}
library(refund)
data(DTI); attach(DTI)
names(DTI)
```

```{r}
DTI.complete <- subset(DTI, complete.cases(DTI))
DTI.baseline <- subset(DTI.complete, visit == 1 & case == 1)
tract <- 1:93
n <- length(unique(DTI.baseline$ID))
```

we will focus on Fractional Anisotropy (FA) along the corpus callosum (CCA) tract collected from the multiple sclerosis (MS) patients without any missing values.

```{r}
dim(DTI.baseline$cca)
```

```{r}
matplot(tract, t(DTI.baseline$cca), 
        type='l', lty=1, col="light grey",
        main = "Diffusion Tensor Imaging : CCA",
        xlab="tract", ylab="Fractional anisotropy (FA)")
sel.crv <- sample(1:n, size = 3, replace = FALSE)
matlines(tract, t(DTI.baseline$cca[sel.crv,]), 
         type='l', lty=1, lwd=2, col = rainbow(3))

```


1-1. Estimation of mean functions

Smooth each curve and take pointwise average

```{r}
library(mgcv)

smooth.curves <- array(0, dim(DTI.baseline$cca))
n <- nrow(DTI.baseline$cca)

for(j in 1:n){
  # j = 1
  fit <- gam(DTI.baseline$cca[j,] ~ s(tract, k = 10, bs = 'cr'), method = "REML")
  # plot(tract, DTI.baseline$cca[j,])
  # lines(tract, fit$fitted)
  smooth.curves[j,] <- fit$fitted
}

matplot(tract, t(DTI.baseline$cca[sel.crv,]), 
         type='l', lty=3, lwd=1, col = rainbow(3))
matlines(tract, t(smooth.curves[sel.crv,]), 
         type='l', lty=1, lwd=1, col = rainbow(3))


```


```{r}
mean.hat <- colMeans(smooth.curves)
matplot(tract, t(DTI.baseline$cca), 
        type='l', lty=1, col="light grey",
        main = "Diffusion Tensor Imaging : CCA",
        xlab="tract", ylab="Fractional anisotropy (FA)")
lines(tract, mean.hat, col='blue', lwd=2)
```



1-2. Estimation of covariance function

Smooth each curve and take sample covariance

```{r}
library(fields)
smooth.cov <- cov(smooth.curves)
image.plot(tract, tract, smooth.cov, 
           main='Smooth covariance of FA (Approach 2)')
```

2. Spectral decomposition of the estimated covariance

From the spectral decomposition of the estimated covariance function we can obtain the estimated eigenfunctions and eigenvalues.

```{r}
svd.result0 <- eigen(smooth.cov, symmetric = TRUE)
# names(svd.result0)

evectors <- svd.result0$vectors[,svd.result0$values > 0]
evalues <- svd.result0$values[svd.result0$values > 0]

head(colSums(evectors^2)) # returns unitary vectors 
```

Since the eigen function returns unitary vectors we need to scale them by sqrt(93)

```{r}
efns0 <- evectors*sqrt(93)
evals0 <- evalues/93
pve <- cumsum(evals0)/sum(evals0)
npc <- sum(pve < 0.95) + 1

# truncated estimated eigen components
efns <- efns0[,1:npc]
evals <- evals0[1:npc]
```

The scree plot is given below:

```{r}
plot(1:20, pve[1:20], pch = 16, 
     ylab="percentage of variance explained", xlab="number of PCs",
     main="scree plot")
abline(h = 0.95, lty=2, col='red')
```

Based on the scree plot we know that the first 5 principal components explain more than 95% of the variabilities in the data.

```{r}
matplot(tract, efns[,1:5], col=rainbow(5), 
        type='l', lty=1, lwd=2,
        ylab="eigenfunctions", xlab="tract",
        main="First 5 eigenfunctions")
```

We could also visualize the effect of each PC by plotting the μ(t) ± 2sqrt(λ_k) * ϕ_k(t).

```{r}
k.pc <- 1
effect <- efns[, k.pc]*2*sqrt(evals[k.pc])
mat <- cbind(mean.hat - effect,  mean.hat + effect)

par(mfrow=c(2,1))
plot(tract, efns[,k.pc], lty=1, lwd=2, type='l', ylim=c(-2,2),
     main = paste0("fPC",k.pc), ylab="", xlab="tract" )
abline(h = 0, lty=3)

matplot(tract, mat, type='p', col=c(2,4), pch = c("-", "+"),
        ylab="", xlab="tract", 
        main = paste0("fPC",k.pc, " (",round(pve[k.pc]*100),"%)"))
lines(tract, mean.hat, lty=1, lwd=1)
```

3. Estimation of scores & fitted curves

The estimated scores can be obtained by calculating

ξ_hat_ik=∫Tϕ_hat_k(t){Y_i(t) − μ_hat (t)}dt.

And the fitted curves are given by

Y_hat_i(t) = μ_hat(t) + ∑k=1npc ξ_hat_ik ϕ_hat_k(t).

```{r}
demeaned <- DTI.baseline$cca - t(matrix(rep(mean.hat, n),
                                        nrow=length(mean.hat)))

scores <- matrix(NA, nrow=n, ncol=npc)
fitted <- array(NA, dim(DTI.baseline$cca))
for(i in 1:n){
  scores[i,] <- colMeans(matrix(rep(demeaned[i,], npc), nrow=93) * efns)
  fitted[i,] <- mean.hat + scores[i,]%*%t(efns)
}

matplot(tract, t(DTI.baseline$cca[sel.crv,]), pch = "o", cex = 0.5,
        ylab="", xlab="tract", main="Fitted curves")
matlines(tract, t(fitted[sel.crv,]), type='l', lwd=2, lty=1)
```

4. Already built-in functions available in R

There are several R functions that implement the fPCA method for the densely observed data (with/without noise):

* fpca.face, fpca.ssvd, fpca2s from the refund package.
  * developed specifically for dense functional data
  * inapplicable to sparse functional data
  * fpca.ssvd and fpca2s requires specifying number of principal components (npc); not possible to select npc based on PVE.

```{r}
?fpca.face
?fpca.ssvd
?fpca2s
  
```



```{r}
res.face <- fpca.face(Y = DTI.baseline$cca, argvals = tract, pve = 0.95)
names(res.face)
```


```{r}
res.face$npc
```

```{r}
efn.face <- res.face$efunctions*sqrt(93)
eval.face <- res.face$evalues/93

matplot(tract, efn.face[,1:5], col=rainbow(5), 
        type='l', lty=1, lwd=2,
        ylab="", xlab="tract",
        main="First 5 eigenfunctions")
```

```{r}
k.pc <- 1
mu.hat <- res.face$mu
effect <- efn.face[,k.pc] * 2* sqrt(eval.face[k.pc])
pve.face <- (cumsum(eval.face)/sum(eval.face))

plot(tract, efn.face[,k.pc], type='l', ylim=c(-2,2))
```

```{r}
matplot(tract, cbind(mu.hat - effect, mu.hat + effect),
        pch = c("-", "+"), ylab="", xlab="tract", col=c(2,4),
        main=paste0("fPC", k.pc,"(", round(pve.face[k.pc]*100) ,"%)"))
lines(tract, mu.hat, lty=1, lwd=1)
```

```{r}
matplot(tract, t(DTI.baseline$cca[sel.crv,]), pch = "o", cex = 0.5,
        ylab="", xlab="tract", main="Fitted curves")
matlines(tract, t(res.face$Yhat[sel.crv,]), type='l', lwd=2, lty=1)
```

To use the fpca.ssvd and fpca2s functions see the following example codes:

```{r}
res.ssvd <- fpca.ssvd(Y = DTI.baseline$cca, npc = 5)
res.2s <- fpca2s(Y = DTI.baseline$cca, npc = 5, argvals = tract)
```

# FPCA tests on my data

ERPs are know to have more curvature in the beginning, thus why I fit the spline with lots of breakpoints in the early portions early. So I will first try smoothing with that Bspline, then I will try the quick automated method.

I don't know yet if I should find the fPCA components based on each subjects data or on every single ERP. So I'm going to program this such that I can swap between them. But this has to be done by an electrode at a time; I'll start with Pz.

```{r}
load(file = "mas_dat.Rdata")

mas_dat_for_fpca <- mas_dat
electrode_used <- 31
categories_used <- c("erotica", "neutral_pe")
mas_dat_1elec <- mas_dat %>% filter(electrode == electrode_used & cat %in% categories_used)
mas_dat_for_fpca <- mas_dat_1elec

```


```{r}
time_ms <- names(mas_dat_for_fpca)[5:ncol(mas_dat_for_fpca)] %>% as.numeric()

mas_key <- mas_dat_for_fpca[,1:4]

mas_just_dat <- mas_dat_for_fpca[,5:ncol(mas_dat_for_fpca)]

ggplot_mas_long <- mas_dat_for_fpca %>% 
  pivot_longer(cols      = !c(1:4), 
               names_to  = "time_ms", 
               values_to = "micro_voltage")

ggplot_mas_long$time_ms <- ggplot_mas_long$time_ms %>% as.numeric()
```


```{r}
ggplot_mas_long %>% 
  ggplot() +
  geom_point(aes(x = time_ms, y = micro_voltage, color = cat),
            alpha = .2, size = .2) +
  scale_x_continuous(breaks = seq(0, 2000, 250)) +
  scale_color_manual(values = c("dodgerblue4", "green")) + 
  theme_classic()

```


1-1. Estimation of mean functions

Smooth each curve and take pointwise average

```{r}
range_time <- range(time_ms)
#breaks = seq(-100, max(range_time), 50)
#breaks <- seq(-100,2000,25)
breaks <- c(-100, 0, 
            seq(5,100,5), 
            seq(110, 300, 10), 
            seq(350, 900, 50),
            seq(1000, 2000, 100))


bspline_basis <- create.bspline.basis(rangeval = range_time,
                                      # nbasis = 42,
                                      norder = 3,
                                      breaks = breaks)

b_vals <- eval.basis(time_ms, bspline_basis)
X_basis <- b_vals
smooth_curves <- array(0, dim(mas_just_dat))
n <- nrow(mas_just_dat)
j = 1

for(j in 1:n){
  y_mas <- unlist(mas_just_dat[j,])
  fit   <- lm(y_mas ~ 0 + X_basis)
  smooth_curves[j,] <- fit$fitted.values
}

```


```{r}
smooth_curves <- smooth_curves %>% as_tibble()

names(smooth_curves) <- names(mas_just_dat)

cbind.data.frame(mas_key, smooth_curves) %>% 
  pivot_longer(cols      = !c(1:4), 
               names_to  = "time_ms", 
               values_to = "micro_voltage") %>% 
  mutate(ms = as.numeric(time_ms)) %>% 
  ggplot() +
  geom_point(aes(x = ms, y = micro_voltage, color = cat),
            alpha = .2, size = .2) +
  scale_x_continuous(breaks = seq(0, 2000, 250)) +
  scale_color_manual(values = c("dodgerblue4", "green")) + 
  theme_classic()
  
```


```{r}
mean_hat <- colMeans(smooth_curves)
```


1-2. Estimation of covariance function

Smooth each curve and take sample covariance

```{r}
smooth_cov <- smooth_curves
image.plot(c(1:1076), c(1:1076), smooth_cov,
           main ='Smooth covariance of FA (Approach 2)')
```


```{r}
library(fields)
smooth.cov <- cov(smooth.curves)
image.plot(tract, tract, smooth.cov, 
           main='Smooth covariance of FA (Approach 2)')
```

2. Spectral decomposition of the estimated covariance

From the spectral decomposition of the estimated covariance function we can obtain the estimated eigenfunctions and eigenvalues.

```{r}
svd.result0 <- eigen(smooth.cov, symmetric = TRUE)
# names(svd.result0)

evectors <- svd.result0$vectors[,svd.result0$values > 0]
evalues <- svd.result0$values[svd.result0$values > 0]

head(colSums(evectors^2)) # returns unitary vectors 
```

Since the eigen function returns unitary vectors we need to scale them by sqrt(93)

```{r}
efns0 <- evectors*sqrt(93)
evals0 <- evalues/93
pve <- cumsum(evals0)/sum(evals0)
npc <- sum(pve < 0.95) + 1

# truncated estimated eigen components
efns <- efns0[,1:npc]
evals <- evals0[1:npc]
```

The scree plot is given below:

```{r}
plot(1:20, pve[1:20], pch = 16, 
     ylab="percentage of variance explained", xlab="number of PCs",
     main="scree plot")
abline(h = 0.95, lty=2, col='red')
```

Based on the scree plot we know that the first 5 principal components explain more than 95% of the variabilities in the data.

```{r}
matplot(tract, efns[,1:5], col=rainbow(5), 
        type='l', lty=1, lwd=2,
        ylab="eigenfunctions", xlab="tract",
        main="First 5 eigenfunctions")
```

We could also visualize the effect of each PC by plotting the μ(t) ± 2sqrt(λ_k) * ϕ_k(t).

```{r}
k.pc <- 1
effect <- efns[, k.pc]*2*sqrt(evals[k.pc])
mat <- cbind(mean.hat - effect,  mean.hat + effect)

par(mfrow=c(2,1))
plot(tract, efns[,k.pc], lty=1, lwd=2, type='l', ylim=c(-2,2),
     main = paste0("fPC",k.pc), ylab="", xlab="tract" )
abline(h = 0, lty=3)

matplot(tract, mat, type='p', col=c(2,4), pch = c("-", "+"),
        ylab="", xlab="tract", 
        main = paste0("fPC",k.pc, " (",round(pve[k.pc]*100),"%)"))
lines(tract, mean.hat, lty=1, lwd=1)
```

3. Estimation of scores & fitted curves

The estimated scores can be obtained by calculating

ξ_hat_ik=∫Tϕ_hat_k(t){Y_i(t) − μ_hat (t)}dt.

And the fitted curves are given by

Y_hat_i(t) = μ_hat(t) + ∑k=1npc ξ_hat_ik ϕ_hat_k(t).

```{r}
demeaned <- DTI.baseline$cca - t(matrix(rep(mean.hat, n),
                                        nrow=length(mean.hat)))

scores <- matrix(NA, nrow=n, ncol=npc)
fitted <- array(NA, dim(DTI.baseline$cca))
for(i in 1:n){
  scores[i,] <- colMeans(matrix(rep(demeaned[i,], npc), nrow=93) * efns)
  fitted[i,] <- mean.hat + scores[i,]%*%t(efns)
}

matplot(tract, t(DTI.baseline$cca[sel.crv,]), pch = "o", cex = 0.5,
        ylab="", xlab="tract", main="Fitted curves")
matlines(tract, t(fitted[sel.crv,]), type='l', lwd=2, lty=1)
```

4. Already built-in functions available in R

There are several R functions that implement the fPCA method for the densely observed data (with/without noise):

* fpca.face, fpca.ssvd, fpca2s from the refund package.
  * developed specifically for dense functional data
  * inapplicable to sparse functional data
  * fpca.ssvd and fpca2s requires specifying number of principal components (npc); not possible to select npc based on PVE.

```{r}
?fpca.face
?fpca.ssvd
?fpca2s
  
```



```{r}
res.face <- fpca.face(Y = DTI.baseline$cca, argvals = tract, pve = 0.95)
names(res.face)
```


```{r}
res.face$npc
```

```{r}
efn.face <- res.face$efunctions*sqrt(93)
eval.face <- res.face$evalues/93

matplot(tract, efn.face[,1:5], col=rainbow(5), 
        type='l', lty=1, lwd=2,
        ylab="", xlab="tract",
        main="First 5 eigenfunctions")
```

```{r}
k.pc <- 1
mu.hat <- res.face$mu
effect <- efn.face[,k.pc] * 2* sqrt(eval.face[k.pc])
pve.face <- (cumsum(eval.face)/sum(eval.face))

plot(tract, efn.face[,k.pc], type='l', ylim=c(-2,2))
```

```{r}
matplot(tract, cbind(mu.hat - effect, mu.hat + effect),
        pch = c("-", "+"), ylab="", xlab="tract", col=c(2,4),
        main=paste0("fPC", k.pc,"(", round(pve.face[k.pc]*100) ,"%)"))
lines(tract, mu.hat, lty=1, lwd=1)
```

```{r}
matplot(tract, t(DTI.baseline$cca[sel.crv,]), pch = "o", cex = 0.5,
        ylab="", xlab="tract", main="Fitted curves")
matlines(tract, t(res.face$Yhat[sel.crv,]), type='l', lwd=2, lty=1)
```

To use the fpca.ssvd and fpca2s functions see the following example codes:

```{r}
res.ssvd <- fpca.ssvd(Y = DTI.baseline$cca, npc = 5)
res.2s <- fpca2s(Y = DTI.baseline$cca, npc = 5, argvals = tract)
```





